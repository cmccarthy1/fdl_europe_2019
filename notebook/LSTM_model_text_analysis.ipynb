{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP for disaster management (Flooding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to act as a development environment for the FDL floods project. \n",
    "\n",
    "The project as completed by the ESA team surrounds the use of image data to create flood segmentation models which can be applied on a Movidius neural network stick.\n",
    "\n",
    "Given the use of image data in this case we have made the decision to approach the problem of disaster management another way namely through the use of natural language processing to bucket tweets into categories so that they can be queried by individuals on the ground "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading appropriate scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l nlp/init.q\n",
    "\\l ml/ml.q\n",
    "\\l ../code/fdl_disasters.q\n",
    "\\l ../code/token_save.p\n",
    ".ml.loadfile`:init.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required python Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa:.p.import[`numpy]`:array\n",
    "plt:.p.import[`matplotlib.pyplot]\n",
    "pd :.p.import[`pandas]\n",
    "\n",
    "// Textual data preprocessing \n",
    "token:.p.import[`keras.preprocessing.text]`:Tokenizer\n",
    "pad  :.p.import[`keras.preprocessing.sequence]`:pad_sequences\n",
    "\n",
    "kl:{.p.import[`keras.layers]x}\n",
    "// Keras layers used\n",
    "seq    :.p.import[`keras.models]`:Sequential\n",
    "dense  :kl`:Dense\n",
    "embed  :kl`:Embedding\n",
    "lstm   :kl`:LSTM\n",
    "spdrop1:kl`:SpatialDropout1D\n",
    "dropout:kl`:Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_1:{rename[;names](\"j*SSS\";enlist\",\")0:`$\":../data/floods/\",x}\n",
    "nms_2:{(\"jSSIPSf*J*S\";enlist\",\")0:`$\":../data/floods/\",x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/ Colorado\n",
    "co :nms_1[\"Developed/2013_Colorado_floods/2013_Colorado_floods-tweets_labeled.csv\"]\n",
    "/ Queensland\n",
    "qld:nms_1[\"Developed/2013_Queensland_floods/2013_Queensland_floods-tweets_labeled.csv\"]\n",
    "/ Alberta\n",
    "alb:nms_1[\"Developed/2013_Alberta_floods/2013_Alberta_floods-tweets_labeled.csv\"]\n",
    "/ Phillipines\n",
    "ph :nms_1[\"Developing/2012_Philipinnes_floods/2012_Philipinnes_floods-tweets_labeled.csv\"]\n",
    "/ India\n",
    "ind:nms_2[\"Developing/2014_India_floods/2014_india_floods.csv\"]\n",
    "/ Pakistan\n",
    "pac:nms_2[\"Developing/2014_Pakistan_floods/2014_pakistan_floods.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Label consolidation and joining of different format data\n",
    "data_b:encodetgt[co,qld,alb,ph;encodebin],encodetgt[ind,pac;encodebin]\n",
    "data_m:encodetgt[co,qld,alb,ph;encodemulti],encodetgt[ind,pac;encodemulti]\n",
    "// Remove capitalization\n",
    "data_m[`tweet_text]:data_b[`tweet_text]:lower data_m`tweet_text\n",
    "// remove data from set which is missing labels\n",
    "inds:exec i from data_m where target<>`not_labeled\n",
    "data_b:data_b@inds\n",
    "data_m:data_m@inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets:data_b\n",
    "save`:tweets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Textual data cleansing\n",
    "rmv_list   :(\"http*\";\"rt\";\"@*\";\"*,\";\"*&*\";\"*[0-9]*\")\n",
    "rmv_single :rmv_master[;\",.:?!/@'\";\"\"]\n",
    "rmv_hashtag:rmv_master[;\"#\";\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5#data_m`tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove non ascii, retweet tag, numerical values, emojis and space hashtags \n",
    "data_m[`tweet_text]:data_b[`tweet_text]:\n",
    " (rmv_ascii rmv_custom[;rmv_list] rmv_hashtag rmv_single@) each data_m`tweet_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5#data_m`tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data analysis steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to take a high level look at the data both in regards to the distribution of classes, explore what underlays the classes themselves and perform some rudimentary sentiment analysis on the data to find positive and negative tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we display the most commonly associated words with a number of the classes within this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudfn[data_m;`affected_individuals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudfn[data_m;`donations_volunteering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudfn[data_m;`sympathy_prayers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the context of the tweets that within the overall dataset it is not surprising that words such as flood and locations such as Pakistan and Kashmir are displayed within a number of the classes. However some displayed words are more informative to the classes,\n",
    "\n",
    "* donations_volunteering:\n",
    "    - affected, donate, rescue, volunteer, people\n",
    "* affected_individuals:\n",
    "    - killed, dead, affected, missing, toll\n",
    "* sympathy_prayers:\n",
    "    - pray, safe, friend, thought, love\n",
    "    \n",
    "The presence of distinct words within each class lends credence to the idea that it should be possible to classify these tweets into their associated categories and generalise this method to new and larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells outline the use of the Kx NLP library to discern positive and negative sentiments from tweets within the corpus. Below we are displaying 5 of the 100 most positive and most negative tweets in the dataset.\n",
    "\n",
    "This allows us to gain some understanding of the state of mind of those individuals affected by the crises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// compute the sentiment of the tweets within the corpus\n",
    "sentiments:.nlp.sentiment each data_m`tweet_text\n",
    "\\c 200 200\n",
    "5?100#data_m[`tweet_text] iasc  sentiments`compound\n",
    "5?100#data_m[`tweet_text] idesc sentiments`compound\n",
    "\\c 20 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category distribution metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important aspect of training machine learning models is an understanding of the distributions of categories within the datasets. This provides a pseudo benchmark from which we can assess the ability of the models to correctly categorize differing classes.\n",
    "\n",
    "For example in an extremely skewed binary classification model with one class `1b` comprising 95% of the target labels a model which has an accuracy on the order of 95% would not be said to have 'learnt' how to distinguish the classes as guessing that all data was labeled `1b` it would achieve this accuracy.\n",
    "\n",
    "As a result we look at other metrics to assess the model performance such as precision, recall and f1-score which are discussed within the whitepaper which details this work from a theoretical viewpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_b:desc count each group data_b`target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt[`:bar][til count distrib_b;value distrib_b;`color pykw `k];\n",
    "plt[`:title][`$\"Distribution of target categories within binary-class dataset\"];\n",
    "plt[`:xlabel][`Category];\n",
    "plt[`:xticks][til count distrib_b;key distrib_b;`rotation pykw `45];\n",
    "plt[`:ylabel][`$\"#Tweets\"];\n",
    "plt[`:show][];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_m:desc count each group data_m`target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt[`:bar][til count distrib_m;value distrib_m;`color pykw `g];\n",
    "plt[`:title][`$\"Distribution of target categories within multi-class dataset\"];\n",
    "plt[`:xlabel][`Category];\n",
    "plt[`:xticks][til count distrib_m;key distrib_m;`rotation pykw `45];\n",
    "plt[`:ylabel][`$\"#Tweets\"];\n",
    "plt[`:show][];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Binary-Class Disaster Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz    :64\n",
    "embed_dim   :100\n",
    "epochs      :10\n",
    "max_nb_words:2000\n",
    "max_seq_len :50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_data_b :npa data_b`tweet_text\n",
    "tweet_vals:py_data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer:token[`num_words pykw max_nb_words;`lower pykw 1b]\n",
    "tokenizer[`:fit_on_texts]tweet_vals;\n",
    "\n",
    "sv_tok:.p.get[`save_token]\n",
    "sv_tok[tokenizer] // Save tokenizer to be used on 'live system'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b:tokenizer[`:texts_to_sequences]tweet_vals\n",
    "X_b:pad[X_b;`maxlen pykw max_seq_len]`\n",
    "\n",
    "Y_b:flip value ohe:.ml.i.onehot1 data_b`target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_b:.ml.traintestsplit[X_b;Y_b;0.1]\n",
    "xtrn_b:tts_b`xtrain;ytrn_b:tts_b`ytrain\n",
    "xtst_b:tts_b`xtest;ytst_b:tts_b`ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_b:seq[];\n",
    "mdl_b[`:add][embed[max_nb_words;embed_dim;`input_length pykw (.ml.shape X_b)1]];\n",
    "mdl_b[`:add]spdrop1[0.2];\n",
    "mdl_b[`:add]lstm[50;pykwargs `dropout`recurrent_dropout!(0.2;0.2)];\n",
    "mdl_b[`:add]dense[2;`activation pykw `softmax];\n",
    "mdl_b[`:compile][pykwargs `loss`optimizer`metrics!(`categorical_crossentropy;`adam;enlist `accuracy)];\n",
    "print mdl_b[`:summary][];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strt:.z.t\n",
    "mdl_b[`:fit][npa xtrn_b;npa ytrn_b;`epochs pykw epochs;`verbose pykw 0];\n",
    "-1\"\\nTraining time = \",string .z.t-strt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scoring[xtst_b;ytst_b;mdl_b;ohe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Multi-Class Disaster Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_data_m :npa data_b`tweet_text\n",
    "tweet_vals:py_data_m\n",
    "tokenizer:token[`num_words pykw max_nb_words;`lower pykw 1b]\n",
    "tokenizer[`:fit_on_texts][tweet_vals];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m:tokenizer[`:texts_to_sequences]tweet_vals\n",
    "X_m:pad[X_m;`maxlen pykw max_seq_len]`\n",
    "\n",
    "Y_m:flip value ohe:.ml.i.onehot1 data_m`target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_m:.ml.traintestsplit[X_m;Y_m;0.1]\n",
    "xtrn_m:tts_m`xtrain;ytrn_m:tts_m`ytrain\n",
    "xtst_m:tts_m`xtest;ytst_m:tts_m`ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_m:seq[];\n",
    "mdl_m[`:add][embed[max_nb_words;embed_dim;`input_length pykw (.ml.shape X_m)1]];\n",
    "mdl_m[`:add]spdrop1[0.1];\n",
    "mdl_m[`:add]lstm[100;pykwargs `dropout`recurrent_dropout!(0.1;0.1)];\n",
    "mdl_m[`:add]dense[7;`activation pykw `softmax];\n",
    "mdl_m[`:compile][pykwargs `loss`optimizer`metrics!(`categorical_crossentropy;`adam;enlist `accuracy)];\n",
    "print mdl_m[`:summary][];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strt:.z.t\n",
    "mdl_m[`:fit][npa xtrn_m;npa ytrn_m;`epochs pykw epochs;`verbose pykw 0];\n",
    "-1\"\\nTraining time = \",string .z.t-strt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scoring[xtst_m;ytst_m;mdl_m;ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_m[`:save][\"../live/multiclass_mdl.h5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of classes within the main dataset it is clear that the classes are imbalanced. To reduce biases which may exist as a result of this imbalance a balanced dataset was built and a model fit with the 'improved model' in order to test improvements that could be gained from the use of a more balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_m:raze{neg[x]?y}[min count each l]each value l:group data_m`target\n",
    "bal_X_m:X_m@inds_m\n",
    "bal_Y_m:Y_m@inds_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_tts_m:.ml.traintestsplit[bal_X_m;bal_Y_m;0.1]\n",
    "xtrn_m:bal_tts_m`xtrain;ytrn_m:bal_tts_m`ytrain\n",
    "xtst_m:bal_tts_m`xtest;ytst_m:bal_tts_m`ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_mdl_m:seq[];\n",
    "bal_mdl_m[`:add][embed[max_nb_words;embed_dim;`input_length pykw (.ml.shape X_m)1]];\n",
    "bal_mdl_m[`:add]spdrop1[0.1];\n",
    "bal_mdl_m[`:add]lstm[100;pykwargs `dropout`recurrent_dropout!(0.1;0.1)];\n",
    "bal_mdl_m[`:add]dense[7;`activation pykw `softmax];\n",
    "bal_mdl_m[`:compile][pykwargs `loss`optimizer`metrics!(`categorical_crossentropy;`adam;enlist `accuracy)];\n",
    "print bal_mdl_m[`:summary][];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strt:.z.t\n",
    "bal_mdl_m[`:fit][npa xtrn_m;npa ytrn_m;`epochs pykw epochs;`verbose pykw 0];\n",
    "-1\"\\nTraining time = \",string .z.t-strt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scoring[xtst_m;ytst_m;bal_mdl_m;ohe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
